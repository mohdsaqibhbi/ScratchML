{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, n_h=4, type='binary', h_func_type='relu', random_state=-1):\n",
    "        \n",
    "        # #hidden_units\n",
    "        self.n_h = n_h\n",
    "        self.type = type\n",
    "        self.h_func_type = h_func_type\n",
    "        self.random_state = random_state\n",
    "        self.functions = {'sigmoid': self.sigmoid,\n",
    "                          'relu': self.relu,\n",
    "                          'tanh': np.tanh}\n",
    "        \n",
    "        self.derivative = {'sigmoid': self.sigmoidDerivative, \n",
    "                           'relu': self.reluDerivative, \n",
    "                           'tanh': self.tanhDerivative}\n",
    "        \n",
    "    def parametersInitialization(self, n_x, n_y):\n",
    "    \n",
    "        if self.random_state != -1:\n",
    "            np.random.seed(self.random_state)\n",
    "            \n",
    "        # shape(#hidden_units, #features)\n",
    "        W1 = np.random.randn(self.n_h, n_x) * 0.01\n",
    "        \n",
    "        # shape(#hidden_units, 1)\n",
    "        b1 = np.zeros((self.n_h, 1))\n",
    "        \n",
    "        # shape(#output_unit, #hidden_units)\n",
    "        W2 = np.random.randn(n_y, self.n_h) * 0.01\n",
    "        \n",
    "        # shape(#output_unit, 1)\n",
    "        b2 = np.zeros((n_y, 1))\n",
    "\n",
    "        self.parameters = {'W1': W1,\n",
    "                      'b1': b1,\n",
    "                      'W2': W2,\n",
    "                      'b2': b2}\n",
    "        \n",
    "    def retrieveParameters(self):\n",
    "    \n",
    "        return self.parameters['W1'], self.parameters['b1'], self.parameters['W2'], self.parameters['b2']\n",
    "    \n",
    "    def retrieveCache(self):\n",
    "    \n",
    "        return self.cache['Z1'], self.cache['A1'], self.cache['Z2'], self.cache['A2']\n",
    "    \n",
    "    def retrieveGrads(self):\n",
    "    \n",
    "        return self.grads['dW1'], self.grads['db1'], self.grads['dW2'], self.grads['db2']\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \n",
    "        return (1 / (1 + np.exp(-z)))\n",
    "    \n",
    "    def relu(self, z):\n",
    "    \n",
    "        return np.maximum(0, z)\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        \n",
    "        return (np.exp(z) / np.sum(np.exp(z), axis=0))\n",
    "    \n",
    "    def sigmoidDerivative(self, Z):\n",
    "        \n",
    "        A = self.sigmoid(Z)\n",
    "        \n",
    "        return (A * (1 - A))\n",
    "    \n",
    "    def reluDerivative(self, Z):\n",
    "        \n",
    "        A = np.where(Z >= 0., 1., 0.)\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    def tanhDerivative(self, Z):\n",
    "        \n",
    "        A = np.tanh(Z)\n",
    "        \n",
    "        return (1 - A**2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "    \n",
    "        W1, b1, W2, b2 = self.retrieveParameters()\n",
    "\n",
    "        # shape(#hidden_units, #samples)\n",
    "        Z1 = np.dot(W1, X) + b1\n",
    "        \n",
    "        # shape(#hidden_units, #samples)\n",
    "        A1 = self.functions[self.h_func_type](Z1)\n",
    "        \n",
    "        # shape(#output_unit, #samples)\n",
    "        Z2 = np.dot(W2, A1) + b2\n",
    "        \n",
    "        if self.type == 'multi':\n",
    "            # shape(#output_unit, #samples)\n",
    "            A2 = self.softmax(Z2)\n",
    "        else:\n",
    "            # shape(#output_unit, #samples)\n",
    "            A2 = self.sigmoid(Z2)\n",
    "\n",
    "        self.cache= {'Z1': Z1,\n",
    "                'A1': A1,\n",
    "                'Z2': Z2,\n",
    "                'A2': A2}\n",
    "\n",
    "        return A2\n",
    "    \n",
    "    def binary_crossEntropy(self, Y_hat, Y):\n",
    "        \n",
    "        # Y_hat : shape(#output_unit, #samples)\n",
    "        # Y : shape(#output_unit, #samples)\n",
    "    \n",
    "        m = Y.shape[1]\n",
    "\n",
    "        # shape(#output_unit, #samples)\n",
    "        loss = - (Y * np.log(Y_hat) + (1 - Y) * np.log(1 - Y_hat))\n",
    "        \n",
    "        # scalar\n",
    "        cost = np.sum(loss) / m\n",
    "\n",
    "        return cost\n",
    "    \n",
    "    def crossEntropy(self, Y_hat, Y):\n",
    "        \n",
    "        # Y_hat : shape(#output_unit, #samples)\n",
    "        # Y : shape(#output_unit, #samples)\n",
    "        \n",
    "        m = Y.shape[1]\n",
    "        \n",
    "        # shape(#samples, )\n",
    "        loss =  - (np.sum(np.log(Y_hat) * (Y), axis=0))\n",
    "        \n",
    "        # scalar\n",
    "        cost = np.sum(loss) / m\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "    \n",
    "        m = X.shape[1]\n",
    "\n",
    "        W1, b1, W2, b2 = self.retrieveParameters()\n",
    "        Z1, A1, Z2, A2 = self.retrieveCache()\n",
    "\n",
    "        # shape(#output_unit, #samples)\n",
    "        dZ2 = A2 - Y\n",
    "        \n",
    "        # shape(#output_unit, #hidden_units)\n",
    "        dW2 = np.dot(dZ2, A1.T) / m\n",
    "        \n",
    "        # shape(#output_unit, 1)\n",
    "        db2 = np.sum(dZ2, axis=1, keepdims=True) / m\n",
    "    \n",
    "        # shape(#hidden_units, #samples)\n",
    "        dZ1 = (np.dot(W2.T, dZ2)) * (self.derivative[self.h_func_type](Z1))\n",
    "        \n",
    "        # shape(#hidden_units, #features)\n",
    "        dW1 = np.dot(dZ1, X.T) / m\n",
    "        \n",
    "        # shape(#hidden_units, 1)\n",
    "        db1 = np.sum(dZ1, axis=1, keepdims=True) / m\n",
    "\n",
    "        self.grads = {'dW1': dW1,\n",
    "                 'db1': db1,\n",
    "                 'dW2': dW2,\n",
    "                 'db2': db2}\n",
    "        \n",
    "    def updateParameters(self, alpha):\n",
    "    \n",
    "        W1, b1, W2, b2 = self.retrieveParameters()\n",
    "\n",
    "        dW1, db1, dW2, db2 = self.retrieveGrads()\n",
    "\n",
    "        # shape(#hidden_units, #features)\n",
    "        W1 = W1 - alpha * dW1\n",
    "        \n",
    "        # shape(#hidden_units, 1)\n",
    "        b1 = b1 - alpha * db1\n",
    "        \n",
    "        # shape(#output_unit, #hidden_units)\n",
    "        W2 = W2 - alpha * dW2\n",
    "        \n",
    "        # shape(#output_unit, 1)\n",
    "        b2 = b2 - alpha * db2\n",
    "\n",
    "        self.parameters = {\"W1\": W1,\n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2}\n",
    "        \n",
    "    def train(self, X, Y, alpha, epochs, print_cost=False):\n",
    "        \n",
    "        # X : shape(#features, #samples)\n",
    "        # Y : shape(1, #samples)\n",
    "        \n",
    "        # #features, #output_unit\n",
    "        n_x, n_y = X.shape[0], Y.shape[0]\n",
    "        \n",
    "        self.parametersInitialization(n_x, n_y)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            \n",
    "            # shape(1, #output_unit)\n",
    "            A2 = self.forward(X)\n",
    "            \n",
    "            if self.type == 'multi':\n",
    "                # scalar\n",
    "                cost = self.crossEntropy(A2, Y)\n",
    "            else:\n",
    "                # scalar\n",
    "                cost = self.binary_crossEntropy(A2, Y)\n",
    "            \n",
    "            self.backward(X, Y)\n",
    "            \n",
    "            self.updateParameters(alpha)\n",
    "            \n",
    "            if print_cost and i % (epochs // 10) == 0:\n",
    "                print (\"Cost after iteration %i : %f\" %(i, cost))\n",
    "                \n",
    "    def predict(self, X):\n",
    "        \n",
    "        W1, b1, W2, b2 = self.retrieveParameters()\n",
    "        \n",
    "        A2 = self.forward(X)\n",
    "        \n",
    "        if self.type == 'multi':\n",
    "            Y_pred = A2.argmax(axis=0)\n",
    "        else:\n",
    "            Y_pred = np.where(A2 > 0.5, 1., 0.)\n",
    "        \n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIrisBinary(path, size=0.2, random_state=0):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sample(frac=1, random_state=random_state)\n",
    "    df.Species.replace(('Iris-setosa', 'Iris-versicolor'), (0., 1.), inplace=True)\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(df.drop(['Species'], axis=1), \n",
    "                                                      df.Species, \n",
    "                                                      test_size=size, \n",
    "                                                      random_state=random_state)\n",
    "    X_train, X_val = X_train.values.T, X_val.values.T\n",
    "    Y_train, Y_val = Y_train.values.reshape(1, -1), Y_val.values.reshape(1, -1)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIrisMulti(path, size=0.2, random_state=0):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df.Species.replace(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), (0, 1, 2), inplace=True)\n",
    "    df = df.sample(frac=1, random_state=random_state)\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(df.drop(['Species'], axis=1), \n",
    "                                                          df.Species, \n",
    "                                                          test_size=size, \n",
    "                                                          random_state=random_state)\n",
    "    X_train, X_val = X_train.values.T, X_val.values.T\n",
    "    Y_train, Y_val = Y_train.values, Y_val.values\n",
    "    Y_train = ((np.arange(np.max(Y_train) + 1) == Y_train[:, None]).astype(float)).T\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 0.692990\n",
      "Cost after iteration 10 : 0.692046\n",
      "Cost after iteration 20 : 0.689178\n",
      "Cost after iteration 30 : 0.680146\n",
      "Cost after iteration 40 : 0.652534\n",
      "Cost after iteration 50 : 0.582169\n",
      "Cost after iteration 60 : 0.462598\n",
      "Cost after iteration 70 : 0.334333\n",
      "Cost after iteration 80 : 0.235743\n",
      "Cost after iteration 90 : 0.170667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         4\n",
      "         1.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = loadIrisBinary('data/Iris_binary.csv', size=0.1)\n",
    "model = ShallowNeuralNetwork(n_h=4, type='binary', h_func_type='tanh', random_state=0)\n",
    "model.train(X_train, Y_train, 0.1, 100, print_cost=True)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(classification_report(Y_val.flatten(), Y_pred.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 1.098791\n",
      "Cost after iteration 15 : 1.095388\n",
      "Cost after iteration 30 : 1.069127\n",
      "Cost after iteration 45 : 0.923583\n",
      "Cost after iteration 60 : 0.677593\n",
      "Cost after iteration 75 : 0.559173\n",
      "Cost after iteration 90 : 0.507121\n",
      "Cost after iteration 105 : 0.473852\n",
      "Cost after iteration 120 : 0.442082\n",
      "Cost after iteration 135 : 0.406681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.88      0.93         8\n",
      "           2       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = loadIrisMulti('data/Iris.csv')\n",
    "model = ShallowNeuralNetwork(n_h=4, type='multi', h_func_type='tanh', random_state=0)\n",
    "model.train(X_train, Y_train, 0.1, 150, print_cost=True)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(classification_report(Y_val, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
