{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gc_utils import dictionary_to_vector, vector_to_dictionary, gradients_to_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, layer_dims, type='binary', h_func_type='relu', random_state=-1):\n",
    "        \n",
    "        self.layer_dims = layer_dims\n",
    "        self.type = type\n",
    "        self.h_func_type = h_func_type\n",
    "        self.random_state = random_state\n",
    "        self.functions = {'sigmoid': self.sigmoid,\n",
    "                          'relu': self.relu,\n",
    "                          'tanh': np.tanh, \n",
    "                          'binary': self.sigmoid, \n",
    "                          'multi': self.softmax}\n",
    "        self.derivative = {'sigmoid': self.sigmoidDerivative, \n",
    "                           'relu': self.reluDerivative, \n",
    "                           'tanh': self.tanhDerivative}\n",
    "        \n",
    "    def parametersInitialization(self):\n",
    "    \n",
    "        if self.random_state != -1:\n",
    "                np.random.seed(self.random_state)\n",
    "\n",
    "        self.parameters = {}\n",
    "        self.L = len(self.layer_dims)\n",
    "\n",
    "        for l in range(1, self.L):\n",
    "\n",
    "            self.parameters['W' + str(l)] = np.random.randn(self.layer_dims[l], self.layer_dims[l-1]) * 0.01\n",
    "            self.parameters['b' + str(l)] = np.zeros((self.layer_dims[l], 1))\n",
    "\n",
    "    def linear(self, A, W, b):\n",
    "    \n",
    "        return np.dot(W, A) + b\n",
    "    \n",
    "    def relu(self, Z):\n",
    "    \n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def sigmoid(self, Z):\n",
    "        \n",
    "        return (1 / (1 + np.exp(-Z)))\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        \n",
    "        return (np.exp(Z) / np.sum(np.exp(Z), axis=0))\n",
    "    \n",
    "    def sigmoidDerivative(self, Z):\n",
    "        \n",
    "        A = self.sigmoid(Z)\n",
    "        \n",
    "        return (A * (1 - A))\n",
    "    \n",
    "    def reluDerivative(self, Z):\n",
    "        \n",
    "        A = np.where(Z >= 0., 1., 0.)\n",
    "            \n",
    "        return A\n",
    "    \n",
    "    def tanhDerivative(self, Z):\n",
    "        \n",
    "        A = np.tanh(Z)\n",
    "        \n",
    "        return (1 - A**2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        self.cache = {'A0': X}\n",
    "        \n",
    "        for l in range(1, self.L-1):\n",
    "\n",
    "            Z = self.linear(self.cache['A' + str(l-1)], self.parameters['W' + str(l)], \n",
    "                            self.parameters['b' + str(l)])\n",
    "            A = self.functions[self.h_func_type](Z)\n",
    "            self.cache['Z' + str(l)] = Z\n",
    "            self.cache['A' + str(l)] = A\n",
    "\n",
    "        ZL = self.linear(self.cache['A' + str((self.L-1)-1)], self.parameters['W' + str(self.L-1)], \n",
    "                         self.parameters['b' + str(self.L-1)])\n",
    "        AL = self.functions[self.type](ZL)\n",
    "        self.cache['Z' + str(self.L-1)] = ZL\n",
    "        self.cache['A' + str(self.L-1)] = AL\n",
    "\n",
    "        return AL\n",
    "    \n",
    "    def binary_crossEntropy(self, AL, Y):\n",
    "        \n",
    "        loss = - (Y * np.log(AL) + (1 - Y) * np.log(1 - AL))\n",
    "        \n",
    "        cost = np.sum(loss) / self.m\n",
    "\n",
    "        return cost\n",
    "    \n",
    "    def crossEntropy(self, AL, Y):\n",
    "        \n",
    "        loss =  - (np.sum(np.log(AL) * (Y), axis=0))\n",
    "        \n",
    "        cost = np.sum(loss) / self.m\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def backward(self, AL, Y):\n",
    "    \n",
    "        self.grads = {}\n",
    "        \n",
    "        dZ = AL - Y\n",
    "        \n",
    "        self.grads['dW' + str(self.L-1)] = np.dot(dZ, self.cache['A' + str((self.L-1)-1)].T) / self.m\n",
    "        self.grads['db' + str(self.L-1)] = np.sum(dZ, axis=1, keepdims=True) / self.m\n",
    "        \n",
    "        for l in reversed(range(1, self.L-1)):\n",
    "            \n",
    "            dZ = (np.dot(self.parameters['W' + str(l+1)].T, dZ)) * (self.derivative[self.h_func_type](\n",
    "                self.cache['Z' + str(l)]))\n",
    "\n",
    "            self.grads['dW' + str(l)] = np.dot(dZ, self.cache['A' + str(l-1)].T) / self.m\n",
    "            self.grads['db' + str(l)] = np.sum(dZ, axis=1, keepdims=True) / self.m\n",
    "            \n",
    "            \n",
    "    def updateparameters(self, alpha):\n",
    "    \n",
    "        for l in range(1, self.L):\n",
    "\n",
    "            self.parameters['W' + str(l)] = self.parameters['W' + str(l)] - alpha * self.grads['dW' + str(l)]\n",
    "            self.parameters['b' + str(l)] = self.parameters['b' + str(l)] - alpha * self.grads['db' + str(l)]\n",
    "            \n",
    "    def train(self, X, Y, alpha, epochs, print_cost=False):\n",
    "        \n",
    "        self.layer_dims.insert(0, X.shape[0])\n",
    "        self.m = X.shape[1]\n",
    "        \n",
    "        self.parametersInitialization()\n",
    "        \n",
    "        for i in range(epochs):\n",
    "        \n",
    "            AL = self.forward(X)\n",
    "\n",
    "            if self.type == 'multi':\n",
    "                cost = self.crossEntropy(AL, Y)\n",
    "            else:\n",
    "                cost = self.binary_crossEntropy(AL, Y)\n",
    "\n",
    "            self.backward(AL, Y)\n",
    "\n",
    "            self.updateparameters(alpha)\n",
    "\n",
    "            if print_cost and i % (epochs // 10) == 0:\n",
    "                    print (\"Cost after iteration %i : %f\" %(i, cost))\n",
    "                    \n",
    "        return self.parameters\n",
    "        \n",
    "    def predict(self, X):\n",
    "    \n",
    "        AL = self.forward(X)\n",
    "        \n",
    "        if self.type == 'multi':\n",
    "            Y_pred = AL.argmax(axis=0)\n",
    "        else:\n",
    "            Y_pred = np.where(AL > 0.5, 1., 0.)\n",
    "\n",
    "        return Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIrisBinary(path, size=0.2, random_state=0):\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sample(frac=1, random_state=random_state)\n",
    "    df.Species.replace(('Iris-setosa', 'Iris-versicolor'), (0., 1.), inplace=True)\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(df.drop(['Species'], axis=1), \n",
    "                                                      df.Species, \n",
    "                                                      test_size=size, \n",
    "                                                      random_state=random_state)\n",
    "    X_train, X_val = X_train.values.T, X_val.values.T\n",
    "    Y_train, Y_val = Y_train.values.reshape(1, -1), Y_val.values.reshape(1, -1)\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIrisMulti(path, size=0.2, random_state=0):\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df.Species.replace(('Iris-setosa', 'Iris-versicolor', 'Iris-virginica'), (0, 1, 2), inplace=True)\n",
    "    df = df.sample(frac=1, random_state=random_state)\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(df.drop(['Species'], axis=1), \n",
    "                                                          df.Species, \n",
    "                                                          test_size=size, \n",
    "                                                          random_state=random_state)\n",
    "    \n",
    "    X_train, X_val = X_train.values.T, X_val.values.T\n",
    "    Y_train, Y_val = Y_train.values, Y_val.values\n",
    "    Y_train = ((np.arange(np.max(Y_train) + 1) == Y_train[:, None]).astype(float)).T\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 0.693380\n",
      "Cost after iteration 10 : 0.692099\n",
      "Cost after iteration 20 : 0.688690\n",
      "Cost after iteration 30 : 0.676167\n",
      "Cost after iteration 40 : 0.636707\n",
      "Cost after iteration 50 : 0.541084\n",
      "Cost after iteration 60 : 0.412634\n",
      "Cost after iteration 70 : 0.281197\n",
      "Cost after iteration 80 : 0.169535\n",
      "Cost after iteration 90 : 0.105444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         9\n",
      "         1.0       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = loadIrisBinary('data/Iris_binary.csv', size=0.2)\n",
    "layer_dims = [5,  1]\n",
    "alpha = 0.1\n",
    "epochs = 100\n",
    "model = DeepNeuralNetwork(layer_dims, h_func_type='relu', random_state=0)\n",
    "parameters = model.train(X_train, Y_train, alpha, epochs, print_cost=True)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(classification_report(Y_pred.flatten(), Y_val.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0 : 1.098396\n",
      "Cost after iteration 10 : 1.094394\n",
      "Cost after iteration 20 : 1.074003\n",
      "Cost after iteration 30 : 1.003746\n",
      "Cost after iteration 40 : 0.865423\n",
      "Cost after iteration 50 : 0.715127\n",
      "Cost after iteration 60 : 0.566849\n",
      "Cost after iteration 70 : 0.479411\n",
      "Cost after iteration 80 : 0.421535\n",
      "Cost after iteration 90 : 0.375075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.88      1.00      0.93         7\n",
      "           2       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.96      0.97      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_val, Y_val = loadIrisMulti('data/Iris.csv')\n",
    "layer_dims = [5, 3]\n",
    "alpha = 0.1\n",
    "epochs = 100\n",
    "model = DeepNeuralNetwork(layer_dims, type='multi', h_func_type='relu', random_state=0)\n",
    "parameters = model.train(X_train, Y_train, alpha, epochs, print_cost=True)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(classification_report(Y_pred.flatten(), Y_val.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
